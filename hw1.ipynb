{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "hw3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB2Pe4Pf3-fN",
        "outputId": "7a26e36f-b105-4804-c33e-1a6cf805a54d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "pd.options.mode.chained_assignment = None \n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FeLCcxf9P9E",
        "outputId": "f84497ed-0f77-43de-e275-f15231dd12e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
        "!tar -xvf mystem-3.0-linux3.1-64bit.tar.gz\n",
        "!mkdir -p /root/.local/bin/\n",
        "!cp mystem /root/.local/bin/mystem\n",
        "\n",
        "from pymystem3 import Mystem"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-07 22:16:58--  http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
            "Resolving download.cdn.yandex.net (download.cdn.yandex.net)... 5.45.205.245, 5.45.205.244, 5.45.205.241, ...\n",
            "Connecting to download.cdn.yandex.net (download.cdn.yandex.net)|5.45.205.245|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: http://cache-mskm904.cdn.yandex.net/download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz [following]\n",
            "--2020-11-07 22:16:58--  http://cache-mskm904.cdn.yandex.net/download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
            "Resolving cache-mskm904.cdn.yandex.net (cache-mskm904.cdn.yandex.net)... 5.45.220.14, 2a02:6b8:0:2002::15\n",
            "Connecting to cache-mskm904.cdn.yandex.net (cache-mskm904.cdn.yandex.net)|5.45.220.14|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16457938 (16M) [application/octet-stream]\n",
            "Saving to: ‘mystem-3.0-linux3.1-64bit.tar.gz.3’\n",
            "\n",
            "mystem-3.0-linux3.1 100%[===================>]  15.70M  8.85MB/s    in 1.8s    \n",
            "\n",
            "2020-11-07 22:17:01 (8.85 MB/s) - ‘mystem-3.0-linux3.1-64bit.tar.gz.3’ saved [16457938/16457938]\n",
            "\n",
            "mystem\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Is2FlaV3-fS",
        "outputId": "c1378522-a823-4432-b559-7def023247a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_df = pd.read_csv(\"train.csv\")\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>url</th>\n",
              "      <th>title</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>m.kp.md</td>\n",
              "      <td>Экс-министр экономики Молдовы - главе МИДЭИ, ц...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>www.kp.by</td>\n",
              "      <td>Эта песня стала известна многим телезрителям б...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>fanserials.tv</td>\n",
              "      <td>Банши 4 сезон 2 серия Бремя красоты смотреть о...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>colorbox.spb.ru</td>\n",
              "      <td>Не Беси Меня Картинки</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>tula-sport.ru</td>\n",
              "      <td>В Новомосковске сыграют следж-хоккеисты алекси...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ... target\n",
              "0   0  ...  False\n",
              "1   1  ...  False\n",
              "2   2  ...  False\n",
              "3   3  ...  False\n",
              "4   4  ...  False\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHK_bZbE3-fX",
        "outputId": "f7e0c4bd-30bc-4f39-c786-506d72a35d14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>url</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>135309</td>\n",
              "      <td>www.kommersant.ru</td>\n",
              "      <td>Шестой кассационный суд в Самаре начнет работу...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>135310</td>\n",
              "      <td>urexpert.online</td>\n",
              "      <td>Что такое индексация алиментов, кем и в каких ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>135311</td>\n",
              "      <td>imperimeha.ru</td>\n",
              "      <td>Женщинам | Империя Меха - Part 12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>135312</td>\n",
              "      <td>national-porn.com</td>\n",
              "      <td>Небритые, волосатые киски: Порно всех стран и ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>135313</td>\n",
              "      <td>2gis.ru</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id                url                                              title\n",
              "0  135309  www.kommersant.ru  Шестой кассационный суд в Самаре начнет работу...\n",
              "1  135310    urexpert.online  Что такое индексация алиментов, кем и в каких ...\n",
              "2  135311      imperimeha.ru                  Женщинам | Империя Меха - Part 12\n",
              "3  135312  national-porn.com  Небритые, волосатые киски: Порно всех стран и ...\n",
              "4  135313            2gis.ru                                                 67"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbTZ8cKb3-fb",
        "outputId": "e33ca282-5138-4a49-ad91-413cec5768ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_df[\"target\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    118594\n",
              "True      16715\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53NpoDv73YN7"
      },
      "source": [
        "Следующие две ячейки могут использоваться в конце, чтобы обновить 100% порнушные и чистые домены. Чисто логически это кажется довольно неплохой добавкой, хотя работает жутко медленно и на деле почти не улучшает скор"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvVvepPKyYdJ"
      },
      "source": [
        "porn_urls = train_df[train_df['target'] == True]['url']\n",
        "porn_urls = set(porn_urls.unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjoCCBst2uS2"
      },
      "source": [
        "non_porn_urls = train_df[train_df['target'] == False]['url']\n",
        "non_porn_urls = set(non_porn_urls.unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E010rXbe30jg"
      },
      "source": [
        "Добавляем самые популярные слова в стоп, чтобы хоть как-то сократить размерность"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpTqo8Gfband"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "russian_stop_words = set(stopwords.words('russian') + ['это', '-', 'эта', 'эти', ',', '.', ')', '('\n",
        "')\\n', '(\\n', '\\n'])\n",
        "english_stop_words = set(stopwords.words('english'))\n",
        "\n",
        "stop_words = russian_stop_words | english_stop_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoKCFKu74BZm"
      },
      "source": [
        "\n",
        "Нормализуем через MyStem, возможно стоит попробовать еще и другие нормализаторы типа стеммера Портера\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ouc5fIJFMo34"
      },
      "source": [
        "\n",
        "normalizer = Mystem()\n",
        "stop_chars = ',.;:!?%$^&-]['\n",
        "\n",
        "def lemmatize(text):\n",
        "  for char in stop_chars:\n",
        "    text = text.replace(char, ' ')\n",
        "  try:\n",
        "    normalized = normalizer.lemmatize(text)\n",
        "    normalized_non_stop = [word for word in normalized if word not in stop_words]\n",
        "    return \"\".join(normalized_non_stop).strip()  \n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    return \"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFJpSgSH4-W-"
      },
      "source": [
        "Добавление url к списку всех слов довольно сильно переобучает модель, получается, что модель настраивается в основном на ссылки и не придает значения тексту, поэтому эту часть стоит оставить закомментированной"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BaJviJ_9TEo"
      },
      "source": [
        "train_df['url_title'] = train_df['url'] + ' ' + train_df['title']\n",
        "test_df['url_title'] = test_df['url'] + ' ' + test_df['title']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej3SaULaYUms"
      },
      "source": [
        "train_df['title_vectorized'] = train_df['url_title'].apply(lemmatize)\n",
        "test_df['title_vectorized'] = test_df['url_title'].apply(lemmatize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoH7n0ILXCCi"
      },
      "source": [
        "X = train_df['title_vectorized'].values\n",
        "y = train_df['target'].astype(int)\n",
        "X_test = test_df['title_vectorized'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBVBf1mC5egS"
      },
      "source": [
        "Тут в основном настраивались параметры min_df и ngram_range, среди всех возможных параметров выбранные показали наилучшее сочетание скора и размерности пространства:\n",
        "\n",
        "(2, 2) - плохой скор\n",
        "\n",
        "(1, 3) - скор не сильно лучше (или буквально такой же), но размерность растет\n",
        "\n",
        "(1, 2) - дал самое оптимальное соотношение\n",
        "\n",
        "Идея по улучшению: некоторые слова могут быть написаны с ошибками,поэтому лучше разбивать не по словам, а по группам символов. Оптимальные параметры (3, 6)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZII9zaSW34j"
      },
      "source": [
        "# stop_words=stop_words, \n",
        "\n",
        "vectorizer = TfidfVectorizer(\n",
        "    lowercase=True, ngram_range=(3, 6), analyzer='char_wb',\n",
        "    min_df=2, max_df=0.8,\n",
        "    sublinear_tf=True\n",
        ")\n",
        "\n",
        "X_transformed = vectorizer.fit_transform(X)\n",
        "X_test_transformed = vectorizer.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg_2ILcg7ewI"
      },
      "source": [
        "def train_model(model, X_train, X_validate, y_train, y_validate):\n",
        "  model.fit(X_train, y_train)\n",
        "  y_pred = model.predict(\n",
        "      X_validate\n",
        "  )\n",
        "  print(\"F1 score: {}\".format(f1_score(y_pred, y_validate)))\n",
        "  print(classification_report(y_validate, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um7-DGxWNXWK"
      },
      "source": [
        "X_train, X_validate, y_train, y_validate = train_test_split(X_transformed, y,\n",
        "                                                            test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zQJuSBn0aHA"
      },
      "source": [
        "Какие модели стоит потестить:\n",
        "\n",
        "-  LogisticRegression  - из всех решателей был выбран liblinear, class_weight = 'balanced', тюн остальных параметров ничего существенного не дал\n",
        "\n",
        "- Приделать к логистической регрессии RF SF: по итогу ожидалось, что качество будет расти от числа estimators, но этого не произошло (возможно это связано с обработкой данных и настройкой лемматайзера и стеммера). При этом пробовались как и семплирование фич, так и семплирование наблюдений\n",
        "\n",
        "\n",
        "- Если останется время попробовать keras или tf?????\n",
        "\n",
        "Что НЕ стоит тестить:\n",
        "- Все, что связано с деревьями (плохо будут работать на таких разреженных данных), сюда же наверное стоит добавить и градиент бустинг\n",
        "\n",
        "- SGDClassifier - потому что это LogisticRegression на минималках\n",
        "\n",
        "- Наивный байас"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlcOs_Q88ubl",
        "outputId": "06f581d6-703c-43a1-82eb-aa1a85d994e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "\n",
        "model = LogisticRegression(solver='liblinear', class_weight='balanced', random_state=42)\n",
        "# model = RandomForestClassifier(random_state=42)\n",
        "train_model(model, X_train, X_validate, y_train, y_validate)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score: 0.98131010705861\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     39137\n",
            "           1       0.98      0.98      0.98      5515\n",
            "\n",
            "    accuracy                           1.00     44652\n",
            "   macro avg       0.99      0.99      0.99     44652\n",
            "weighted avg       1.00      1.00      1.00     44652\n",
            "\n",
            "CPU times: user 8.77 s, sys: 4.96 s, total: 13.7 s\n",
            "Wall time: 8.01 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cC3mYTbEs8TZ",
        "outputId": "e078f653-a4c7-4684-a2b4-240dab67adae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "test_df[\"target\"] = model.predict(X_test_transformed).astype(bool)\n",
        "for url in porn_urls:\n",
        "  test_df[(test_df['url'] == url) & (test_df['target'] == False)]['target'] = True\n",
        "for url in non_porn_urls:\n",
        "  test_df[(test_df['url'] == url) & (test_df['target'] == True)]['target'] = False\n",
        "test_df[[\"id\", \"target\"]].to_csv(\"ml_baseline.csv\", index=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 7min 6s, sys: 1.28 s, total: 7min 7s\n",
            "Wall time: 7min 9s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VX7a2eMYAsJ_"
      },
      "source": [
        "Идеи:\n",
        "\n",
        "Настроить умное приведение к нижнему регистру - Dick Hammigton классифицирует как порно, а не как человека( (не сделано)\n",
        "\n",
        "Разбивать не по словам, а по n символам, чтобы обработать ошибки в тайтлах по типу гомосексулст, порн, и тп (влечет за собой проблемы из графы Не все так однозначно) (сделано)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSMSmBUk3-fy"
      },
      "source": [
        "### Не все так однозначно\n",
        "\n",
        "**не порно**:\n",
        "- Болезни опорно-двигательной системы и импотенция: взаимосвязь\n",
        "- Транссексуальные рыбы - National Geographic Россия: красота мира в каждом кадре\n",
        "- Групповая обзорная экскурсия по Афинам - цена €50\n",
        "- Больного раком Задорнова затравили в соцсетях.\n",
        "- Гомосексуалисты на «Первом канале»? Эрнст и Галкин – скрытая гей-пара российского шоу-бизнеса | Заметки о стиле, моде и жизни\n",
        "\n",
        "**порно**:\n",
        "- Отборная домашка\n",
        "- Сюзанна - карьера горничной / Susanna cameriera perversa (с русским переводом) 1995 г., DVDRip"
      ]
    }
  ]
}